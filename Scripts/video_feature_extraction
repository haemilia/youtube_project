from pathlib import Path
import useful as use
import pandas as pd
import numpy as np
priv = use.get_priv()
global DATA_PATH
DATA_PATH = Path(priv["DATA_PATH"])
hf_token = priv["HF_API_KEY"]
features_dir = DATA_PATH / "dataset"

unpopular_df_raw = pd.read_pickle(DATA_PATH/"temp/raw/unpopular_raw.pkl")

from demo import download_video_with_id
import feature_extraction as fe
import pickle
import sys

# Your DataFrame of video IDs
unpopular_id = unpopular_df_raw["id"]

# Prepare model and preprocessor
device = fe.set_device()
vid_processor = fe.load_video_processor(hf_token)
vid_model = fe.load_video_model(device, hf_token)

xclip_filename = features_dir/"unpopular_video_features.pkl"
if (xclip_filename).exists():
    with open(xclip_filename,'rb') as fr:
        xclip_features_dict = pickle.load(fr)
else:
    xclip_features_dict = {}

l1_filename = features_dir/"unpopular_l1_norms.pkl"
if (l1_filename).exists():
    with open(l1_filename,'rb') as fr:
        l1_features_dict = pickle.load(fr)
else:
    l1_features_dict = {}

progress_save_path = DATA_PATH / "temp/progress.txt"

if (progress_save_path).exists():
    with open(progress_save_path, "r") as fr:
        start_from = int(fr.read())
else:
    start_from = 0

error_message = "Completed without catching error"
ids_to_query = unpopular_id[start_from:]
total = len(ids_to_query)

# Define the full path to the log file on the shared drive
# changed to local path for now
shared_drive_path = Path("../LOG")
log_file_path = shared_drive_path / "progress.log"

# Ensure the directory exists
shared_drive_path.mkdir(parents=True, exist_ok=True)
temp_dir = Path("../temp")
use.create_directory_if_not_exists(temp_dir)

with open(log_file_path, 'a') as log_file:
    original_stdout = sys.stdout
    sys.stdout = log_file
    try:
        for i, video_id in enumerate(ids_to_query):
            print(f"{i+1} / {total}")
            # download video to temp
            vid_path = download_video_with_id(video_id, temp_dir, cookie_path="../cookies.txt")

            # extract features
            print("Extracting feature vectors...")
            xclip_features, l1_features = fe.feature_from_video_with_l1(vid_path,
                                                processor=vid_processor,
                                                model=vid_model,
                                                device=device,
                                                num_of_frames=8)
            # store features
            print("Storing feature vectors...")
            xclip_features_dict[video_id] = xclip_features
            l1_features_dict[video_id] = l1_features
            with open(features_dir/"unpopular_video_features.pkl", "wb") as fw:
                pickle.dump(xclip_features, fw)
            with open(features_dir/"unpopular_l1_norms.pkl",'wb') as fw:
                pickle.dump(l1_features_dict, fw)
            with open(DATA_PATH / "temp/progress.txt", "w") as fw:
                fw.write(str(start_from +i))

            # delete video from temp
            if vid_path is None:
                vid_path = temp_dir / f"{video_id}.mp4"
            vid_path.unlink(missing_ok=True)
            print(f"Deleted {video_id}.mp4")
    except Exception as e:
        error_message = str(e)
    sys.stdout = original_stdout

from datetime import datetime

def write_termination_file_pathlib(reason, shared_drive_path_str):
    shared_drive_path = Path(shared_drive_path_str)
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    filename = f"URGENT_termination_status_{timestamp}.txt"
    full_path = shared_drive_path / filename

    try:
        full_path.write_text(f"Loop terminated at: {timestamp}\nReason: {reason}\n")
        print(f"Termination status written to: {full_path}")
    except Exception as e:
        print(f"Error writing to shared drive: {e}")

write_termination_file_pathlib(error_message, Path("../LOG"))